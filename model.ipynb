{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Install Requirements (Run this first)\n",
    "# ===============================\n",
    "# pip install datasets sklearn pandas xgboost joblib\n",
    "\n",
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "# ===============================\n",
    "# Load Dataset with Stratification\n",
    "# ===============================\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"civil_comments\", split=\"train[:100000]\")  # Use more data\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# ===============================\n",
    "# Investigate Toxicity Distribution\n",
    "# ===============================\n",
    "print(\"Toxicity distribution:\", df['toxicity'].describe())\n",
    "\n",
    "# Create binary target - toxic or not toxic\n",
    "df['target'] = (df['toxicity'] >= 0.5).astype(int)\n",
    "print(\"Class distribution:\", np.bincount(df['target']))\n",
    "print(f\"Positive class percentage: {df['target'].mean()*100:.2f}%\")\n",
    "\n",
    "# Example toxic comments\n",
    "print(\"\\nExample toxic comments:\")\n",
    "for text in df[df['target'] == 1]['text'].sample(3).values:\n",
    "    print(f\"- {text[:100]}...\")\n",
    "\n",
    "# ===============================\n",
    "# Feature Engineering - Use Character-Level Features\n",
    "# ===============================\n",
    "print(\"\\nExtracting features...\")\n",
    "# Use character n-grams instead of words for better signal\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',  # Character n-grams including word boundaries\n",
    "    ngram_range=(3, 5),  # Character sequences of length 3-5\n",
    "    max_features=20000,  # Use more features\n",
    "    min_df=5,\n",
    "    max_df=0.7  # Ignore very common character sequences\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['target'].values\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# ===============================\n",
    "# Stratified Sampling for Train/Test Split\n",
    "# ===============================\n",
    "# Use stratified sampling to ensure both splits have toxic examples\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Testing distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Free memory\n",
    "del X\n",
    "gc.collect()\n",
    "\n",
    "# ===============================\n",
    "# Train a Simpler Model First - Logistic Regression\n",
    "# ===============================\n",
    "print(\"Training logistic regression model...\")\n",
    "model = LogisticRegression(\n",
    "    C=1.0,\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    max_iter=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all cores\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# Evaluate Model\n",
    "# ===============================\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ===============================\n",
    "# Sanity Check Test Cases\n",
    "# ===============================\n",
    "sample_comments = [\n",
    "    \"You're so wonderful and helpful!\",\n",
    "    \"You're a complete waste of oxygen.\",\n",
    "    \"What a dumb idea. You're clueless.\",\n",
    "    \"I appreciate your perspective.\"\n",
    "]\n",
    "\n",
    "print(\"\\nSample Toxicity Predictions:\")\n",
    "for comment in sample_comments:\n",
    "    vec = vectorizer.transform([comment])\n",
    "    pred = model.predict(vec)[0]\n",
    "    prob = model.predict_proba(vec)[0][1]\n",
    "    print(f\"{comment}\")\n",
    "    print(f\"→ Prediction: {'Toxic' if pred == 1 else 'Non-toxic'} ({prob:.3f})\")\n",
    "    \n",
    "    # Find top features for this prediction\n",
    "    if vec.nnz > 0:  # If we have any features\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        coefs = model.coef_[0]\n",
    "        \n",
    "        # Get feature indices and values\n",
    "        indices = vec.nonzero()[1]\n",
    "        feature_weights = [(feature_names[i], vec[0, i] * coefs[i]) for i in indices]\n",
    "        sorted_weights = sorted(feature_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        # Show top contributing features\n",
    "        print(\"→ Top contributing features:\", sorted_weights[:5])\n",
    "    print()\n",
    "\n",
    "# ===============================\n",
    "# Save Model + Vectorizer\n",
    "# ===============================\n",
    "joblib.dump(model, \"toxic_comment_model_logistic.pkl\")\n",
    "joblib.dump(vectorizer, \"toxic_vectorizer_char.pkl\")\n",
    "print(\"Saved model and vectorizer.\")\n",
    "\n",
    "# ===============================\n",
    "# Download from Colab (Optional)\n",
    "# ===============================\n",
    "from google.colab import files\n",
    "\n",
    "files.download(\"toxic_comment_model_logistic.pkl\")\n",
    "files.download(\"toxic_vectorizer_char.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
